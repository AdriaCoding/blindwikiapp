\section{Introducción}

BlindWiki es una red de audio geolocalizada que permite a personas con discapacidad visual total o parcial compartir sus experiencias mediante grabaciones sonoras utilizando teléfonos inteligentes. Creada en 2014 por Antoni Abad, la plataforma no se limita a documentar dificultades y barreras urbanas, sino que constituye un repositorio de experiencias, opiniones e historias que genera una cartografía colaborativa y creativa de lo invisible.

El proyecto tuvo su origen como una iniciativa para dar voz a las personas con discapacidad visual, permitiéndoles documentar y compartir su percepción única del entorno urbano. Desde su creación, BlindWiki ha experimentado una notable expansión internacional, desarrollándose en ciudades como Roma (2014-2015), Sydney (2015), Berlín y Wrocław (2016), Venecia (2017), Valencia (2020) y São Paulo (2022), adaptándose a cada contexto cultural y lingüístico.

La aplicación móvil de BlindWiki, disponible tanto para Android como iOS, permite a los participantes grabar audio específico del lugar y publicarlo inmediatamente en la plataforma. Los usuarios pueden desplazarse por sus ciudades mientras publican y reciben descripciones de audio geolocalizadas, historias, obstáculos o crónicas previamente contribuidas a través de la app. Esta funcionalidad facilita la creación de un mapa sensorial colectivo que enriquece la experiencia de navegación urbana para personas con discapacidad visual.

\subsection{Motivación y Objetivos}

La necesidad de rediseñar la aplicación surge de los avances tecnológicos en los dispositivos móviles y sus sistemas operativos, así como de la comunidad internacional de usuarios que demanda mejoras en la accesibilidad y funcionalidad.

El stack tecnológico de la aplicación original se compone de PhoneGap/Cordova como framework base para el empaquetado, e Ionic 1 con Angular.js para la interfaz de usuario y lógica de la aplicación. Esta arquitectura, aunque permitió un desarrollo multiplataforma eficiente en su momento, ha quedado obsoleta frente a los estándares actuales de desarrollo móvil, lo que dificulta la implementación de nuevas funcionalidades y afecta al rendimiento en dispositivos modernos.

Para abordar estos desafíos, se ha desarrollado BlindWiki 2.0, una aplicación completamente rediseñada utilizando tecnologías modernas y eficientes. El nuevo stack tecnológico se basa en \textbf{React Native} y \textbf{Expo}.

Además, la expansión internacional del proyecto ha llevado a la necesidad de superar las barreras lingüísticas que limitan la comunicación entre participantes de diferentes países. Para lograr este objetivo, es preciso implementar una capa de inteligencia artificial basada en modelos avanzados de procesamiento de lenguaje natural y audio. 

Específicamente, se utilizan tres componentes principales:
\begin{itemize}
    \item \textbf{Identificación automática de idioma:} Mediante el modelo \TODO, que permite detectar el idioma original de cada grabación de audio.
    \item \textbf{Transcripción de audio a texto:} Utilizando el modelo \TODO para convertir las grabaciones de audio en texto en su idioma original.
    \item \textbf{Traducción de audio a audio:} \TODO
\end{itemize}

\subsection{Objectivos}