\section{Estado del Arte}

En esta sección discutiremos los últimos avances en tecnologías de desarrollo de aplicaciones móviles multiplataforma, y el estado del arte en la traducción automatica Speech-to-Speech (S2ST) y el reconocimiento automático del habla (ASR).

\subsection{Desarrollo de Aplicaciones Móviles Multiplataforma}

El desarrollo de aplicaciones multiplataforma ha evolucionado significativamente durante la última década como respuesta a la fragmentación del mercado móvil entre Android (71.9\%) e iOS (27.68\%) \cite{statcounter2025}, y la necesidad de optimizar recursos de desarrollo. El concepto fundamental \textit{"write once, run everywhere"} constituye el núcleo de esta filosofía.

Históricamente, esta tecnología evolucionó desde enfoques basados en WebView (PhoneGap/Cordova) hacia frameworks de compilación a código nativo, hasta las soluciones actuales que equilibran rendimiento nativo con eficiencia de desarrollo. El rendimiento de nativo es de especial interés para el proyecto blind wiki, ya que eso proporciona una mayor compatibilidad con los lectores de pantalla (TalkBack en Android y VoiceOver en iOS).

\subsubsection{Frameworks Considerados}

\paragraph{Flutter (Google)}
Framework que utiliza Dart como lenguaje y un motor de renderizado propio (Skia). Su arquitectura se compone de tres capas: el framework Dart, el motor C/C++ con Skia, y los wrappers específicos de plataforma. Entre sus ventajas, Flutter ofrece un rendimiento similar al nativo con 60 FPS en animaciones complejas, una interfaz de usuario consistente y personalizable en todas las plataformas, y widgets adaptables tanto de Material Design como de Cupertino. Además, cuenta con sistema de árbol semántico con descripciones para cada widget, perfectamente integrado con las APIs nativas de accesibilidad (TalkBack/VoiceOver).

\paragraph{React Native (Meta)}
Utiliza JavaScript y React para crear aplicaciones móviles mediante una arquitectura puente que conecta JavaScript con componentes nativos de la plataforma. Sus ventajas incluyen el aprovechamiento del ecosistema JavaScript/npm, la utilización de componentes UI nativos reales, y la facilidad de transición desde el desarrollo web. Además, React Native ofrece integración directa con los componentes nativos de accesibilidad, heredando automáticamente las mejoras del sistema operativo. No obstante, el puente JavaScript-Nativo puede limitar el rendimiento en comparación con Flutter.


\subsubsection{Análisis Comparativo}
En la siguiente tabla \ref{tab:framework-comparison} se muestra un resumen de las características de los frameworks considerados para el desarrollo de la aplicación blind wiki.
\begin{table}[ht]
    \centering
    \caption{Comparación de Frameworks Multiplataforma}
    \label{tab:framework-comparison}
    \begin{tabular}{|l|c|c|}
        \hline
        \textbf{Característica} & \textbf{Flutter} & \textbf{React Native} \\
        \hline
        Lenguaje & Dart & JavaScript \\
        \hline
        Arquitectura UI & Motor propio & Componentes nativos \\
        \hline
        Rendimiento & Excelente & Bueno \\
        \hline
        Hot Reload & Sí & Sí \\
        \hline
        Curva Aprendizaje & Moderada & Baja (dev JS) \\
        \hline
        Madurez & Media (2017) & Alta (2015) \\
        \hline
        Accesibilidad & Árbol semántico & Componentes nativos \\
        \hline
    \end{tabular}
\end{table}

Para el desarrollo de BlindWiki 2.0, se ha optado por React Native, por su mayor madurez, y por que presenta una curva de aprendizaje más suave para el desarrollador. Las limitaciones en cuanto a al rendimiento de React Native en comparación con Flutter no son críticas para el proyecto, ya que los principales cuellos de botella son las conexiones con el servidor y no el rendimiento interno de la aplicación.

\subsection{Reconocimiento Automático de Habla (ASR)}
Nos interesa representar las notas de voz de los usuarios de blind wiki en formato de texto, para facilitar los procesos posteriores de traducción y tagging. Esta tarea se conoce como Automatic Speech Translation (ASR).

En la actualidad existen múltiples modelos preentrenados para esta tarea, y un conjunto de benchmarks para evaluar su rendimiento.

explicar aquí brevemente las benchmarks que luego usaremos en la comparación

\subsubsection{Whisper (OpenAI)}


\subsection{Traducción de Texto a Texto (T2TT)}

\subsection{Modelos de traduccion de Voz a Texto (S2TT) vs modelos en cascada}
Una de las preguntas que nos plantea el proyecto es si es conveniente usar primero un modelo de ASR y luego un modelo de T2TT, lo cual se conoce como un esquema en cascada, o si es mejor usar un modelo que genere las traducciónes directamente del audio (S2TT).

According to the most recent IWSLT Evaluation Campaign \cite{iwslt-findings}, y otros estudios \cite{etchegoyhen2022cascade} \cite{Sethiya2025}, los modelos en cascada demuestran ser más efectivos que los modelos directos en cuanto a calidad de traducción, especialmente para los idiomas con baja disponibilidad de datos, como el gallego, que es uno de los idiomas objetivo de la aplicación.

\subsection{Identificación automática de tags}

