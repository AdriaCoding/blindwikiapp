@inproceedings{jia2022cvss,
    title={{CVSS} Corpus and Massively Multilingual Speech-to-Speech Translation},
    author={Jia, Ye and Tadmor Ramanovich, Michelle and Wang, Quan and Zen, Heiga},
    booktitle={Proceedings of Language Resources and Evaluation Conference (LREC)},
    pages={6691--6703},
    year={2022}
}

// Speaker-preserving model (unavailable on hugging-face)
@misc{jia2022translatotron2highqualitydirect,
      title={Translatotron 2: High-quality direct speech-to-speech translation with voice preservation}, 
      author={Ye Jia and Michelle Tadmor Ramanovich and Tal Remez and Roi Pomerantz},
      year={2022},
      eprint={2107.08661},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2107.08661}, 
}
// Speaker-preserving model (unavailable on hugging-face)
@misc{zhou2024preservingspeakerinformationdirect,
      title={Preserving Speaker Information in Direct Speech-to-Speech Translation with Non-Autoregressive Generation and Pretraining}, 
      author={Rui Zhou and Akinori Ito and Takashi Nose},
      year={2024},
      eprint={2412.07316},
      archivePrefix={arXiv},
      primaryClass={cs.SD},
      url={https://arxiv.org/abs/2412.07316}, 
}
@misc{statcounter2025,
  author = {StatCounter},
  title = {Mobile Operating System Market Share Worldwide - March 2025},
  year = {2025},
  url = {https://gs.statcounter.com/os-market-share/mobile/worldwide},
  note = {Recuperado de StatCounter Global Stats}
}
@article{SETHIYA2025101751,
title = {End-to-End Speech-to-Text Translation: A Survey},
journal = {Computer Speech \& Language},
volume = {90},
pages = {101751},
year = {2025},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2024.101751},
url = {https://www.sciencedirect.com/science/article/pii/S0885230824001347},
author = {Nivedita Sethiya and Chandresh Kumar Maurya},
keywords = {Speech-to-text translation, Automatic speech recognition, Machine translation, Modality bridging},
abstract = {Speech-to-Text (ST) translation pertains to the task of converting speech signals in one language to text in another language. It finds its application in various domains, such as hands-free communication, dictation, video lecture transcription, and translation, to name a few. Automatic Speech Recognition (ASR), as well as Machine Translation(MT) models, play crucial roles in traditional ST translation, enabling the conversion of spoken language in its original form to written text and facilitating seamless cross-lingual communication. ASR recognizes spoken words, while MT translates the transcribed text into the target language. Such integrated models suffer from cascaded error propagation and high resource and training costs. As a result, researchers have been exploring end-to-end (E2E) models for ST translation. However, to our knowledge, there is no comprehensive review of existing works on E2E ST. The present survey, therefore, discusses the works in this direction. We have attempted to provide a comprehensive review of models employed, metrics, and datasets used for ST tasks, providing challenges and future research direction with new insights. We believe this review will be helpful to researchers working on various applications of ST models.}
}