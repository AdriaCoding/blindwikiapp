{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EXA5LSg6uFvT",
    "outputId": "6e382d9c-fb82-414c-9c6b-5c888a98813b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adria\\dev\\blindwikiapp\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Adria\\dev\\blindwikiapp\\.venv\\Lib\\site-packages\\speechbrain\\utils\\fetching.py:151: UserWarning: Using SYMLINK strategy on Windows for fetching potentially requires elevated privileges and is not recommended. See `LocalStrategy` documentation.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Adria\\dev\\blindwikiapp\\.venv\\Lib\\site-packages\\speechbrain\\utils\\autocast.py:188: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  wrapped_fwd = torch.cuda.amp.custom_fwd(fwd, cast_inputs=cast_inputs)\n",
      "C:\\Users\\Adria\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\inspect.py:1007: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "c:\\Users\\Adria\\dev\\blindwikiapp\\.venv\\Lib\\site-packages\\speechbrain\\utils\\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "import torchaudio\n",
    "import librosa\n",
    "import torch\n",
    "import pickle as pkl\n",
    "import audiofile\n",
    "from soundfile import LibsndfileError\n",
    "from speechbrain.inference.classifiers import EncoderClassifier\n",
    "\n",
    "# Clear the model cache\n",
    "cache_dir = \"C:/Users/Adria/.cache/huggingface/hub/models--speechbrain--lang-id-voxlingua107-ecapa\"\n",
    "if os.path.exists(cache_dir):\n",
    "    shutil.rmtree(cache_dir)\n",
    "\n",
    "# Also remove the tmp directory\n",
    "if os.path.exists(\"tmp\"):\n",
    "    shutil.rmtree(\"tmp\")\n",
    "\n",
    "# Then try loading the model again\n",
    "from speechbrain.inference.classifiers import EncoderClassifier\n",
    "language_id = EncoderClassifier.from_hparams(source=\"speechbrain/lang-id-voxlingua107-ecapa\", savedir=\"tmp\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j6Xay9snuFvU"
   },
   "outputs": [],
   "source": [
    " # to be run on top of the 'uploads' directory containing the audio files\n",
    "path = os.path.join(os.getcwd(), \"uploads\")\n",
    "files = os.listdir(path)\n",
    "supported_audio_formats = [\"wav\",\"mp3\"]\n",
    "files = [file for file in files if file[-3:] in supported_audio_formats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7ZATwURSuFvU",
    "outputId": "cfd870f8-9b09-4d66-e18c-a49ea2d126ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('c:\\\\Users\\\\Adria\\\\dev\\\\blindwikiapp\\\\notebooks\\\\uploads',\n",
       " ['acoruna_barco_m67780_a84524_audio_converted.mp3',\n",
       "  'barcelona_Ovvero_m68255_a84999_audio_converted.mp3',\n",
       "  'berlin_Dirk_m67384_a84128_audio_converted.mp3',\n",
       "  'cuenca_Amalia_m69879_a86623_audio_converted.mp3',\n",
       "  'elbarcelonC3A8s_Martagosa_m71623_a88367_audio_converted.mp3'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FCFluErsuFvV",
    "outputId": "08b374f0-96e4-47fc-db05-5a1374cbbb9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mp3'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_ends = set()\n",
    "for file in files:\n",
    "    file_ends.add(file[-3:])\n",
    "file_ends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4p4qdGAuuFvV",
    "outputId": "92031d54-6f42-4179-aa21-2ece69e01cc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "       -9.4561778e-07, -6.0664206e-07, -3.3898604e-07],\n",
       "      shape=(254016,), dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the path variable you already defined\n",
    "file_path = os.path.join(path, \"barcelona_Ovvero_m68255_a84999_audio_converted.mp3\")\n",
    "os.path.exists(file_path)\n",
    "signal, sampling_rate = audiofile.read(file_path)\n",
    "signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LHWTPQDNuFvV",
    "outputId": "384d3a8e-1cdf-4b84-a10d-bb9875a3d1b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acoruna_barco_m67780_a84524_audio_converted.mp3': 'Galician', 'barcelona_Ovvero_m68255_a84999_audio_converted.mp3': 'Bosnian', 'berlin_Dirk_m67384_a84128_audio_converted.mp3': 'German', 'cuenca_Amalia_m69879_a86623_audio_converted.mp3': 'Spanish', 'elbarcelonC3A8s_Martagosa_m71623_a88367_audio_converted.mp3': 'Catalan'}\n"
     ]
    }
   ],
   "source": [
    "# Replace the last cell in language_tagger.ipynb\n",
    "predictions_dict = {}  # Change from list to dictionary\n",
    "corrupted_files = []\n",
    "predictions_file = \"predictions_dict.pkl\"\n",
    "i = 0\n",
    "for file in files:\n",
    "    #print(file)\n",
    "    i+=1\n",
    "    try:\n",
    "        signal, sr = audiofile.read(os.path.join(path, file))\n",
    "    except LibsndfileError as e:\n",
    "        print(\"Corrupt file\", file)\n",
    "        print(e)\n",
    "        corrupted_files.append(file)\n",
    "        continue\n",
    "    prediction = language_id.classify_batch(torch.tensor(signal))\n",
    "    language = prediction[3][0].split(\":\")[1].strip()\n",
    "    predictions_dict[file] = language  # Save as dictionary with filename as key\n",
    "    if i % 100 == 0:\n",
    "        print(f\"Iteration {i} completed reaching update...\")\n",
    "        with open(os.path.join(\"data\", predictions_file), \"wb\") as f:  # Save to data directory\n",
    "            pkl.dump(predictions_dict, f)\n",
    "print(predictions_dict)\n",
    "with open(os.path.join(\"data\", predictions_file), \"wb\") as f:  # Save to data directory\n",
    "    pkl.dump(predictions_dict, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
