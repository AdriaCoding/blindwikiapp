{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "506507d4",
   "metadata": {},
   "source": [
    "# BlindWiki AI Pipeline Summary\n",
    "\n",
    "This notebook provides a comprehensive summary of the AI processing pipeline developed for the BlindWiki application. The pipeline consists of several interconnected components that together provide automatic processing of audio notes, including:\n",
    "\n",
    "1. Language identification\n",
    "2. Speech-to-text transcription\n",
    "3. Translation to English\n",
    "4. Text analysis and tagging\n",
    "\n",
    "Below we explain each component and how they work together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5ce0b0",
   "metadata": {},
   "source": [
    "## 1. Language Identification (`language_tagger.ipynb`)\n",
    "\n",
    "The first step in the pipeline is to identify the language of each audio recording. This is done using a pre-trained language identification model from SpeechBrain.\n",
    "\n",
    "### Key components:\n",
    "\n",
    "- **Model**: SpeechBrain's `EncoderClassifier` with the pre-trained `speechbrain/lang-id-voxlingua107-ecapa` model\n",
    "- **Process**: \n",
    "  1. Audio files are loaded and processed in batches\n",
    "  2. The model predicts the language for each audio file\n",
    "  3. Results are saved to a pickle file for later use\n",
    "\n",
    "### Output:\n",
    "- A dictionary mapping file names to predicted languages\n",
    "\n",
    "### Notes:\n",
    "- The model supports 107 languages through the VoxLingua107 dataset\n",
    "- Corrupted audio files are detected and logged separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e27a0fc",
   "metadata": {},
   "source": [
    "## 2. Statistical Analysis (`statistical_analyisis_on_languages.ipynb`)\n",
    "\n",
    "This notebook performs statistical analysis on the language identification results to understand the distribution of languages in the dataset.\n",
    "\n",
    "### Key components:\n",
    "\n",
    "- **Data Loading**: Loads pickle files containing language identification results\n",
    "- **Analysis**: \n",
    "  1. Counts occurrences of each language\n",
    "  2. Visualizes language distribution\n",
    "  3. Allows filtering languages by frequency threshold\n",
    "\n",
    "### Output:\n",
    "- `file_language.csv`: A CSV file mapping audio files to their detected languages\n",
    "- Visualization of language distribution\n",
    "\n",
    "### Notes:\n",
    "- This step helps in understanding the diversity of languages in the dataset\n",
    "- Can be used to decide which languages to prioritize for transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f54a4de",
   "metadata": {},
   "source": [
    "## 3. Speech-to-Text Transcription (`get_transcriptions_on_language.ipynb`)\n",
    "\n",
    "This notebook transcribes audio files based on their identified language using OpenAI's Whisper model.\n",
    "\n",
    "### Key components:\n",
    "\n",
    "- **Model**: OpenAI's `whisper-tiny` model (smaller version of Whisper)\n",
    "- **Data**: Uses `file_language.csv` from the statistical analysis\n",
    "- **Process**:\n",
    "  1. Groups audio files by language\n",
    "  2. For each language:\n",
    "     - Sets up language-specific decoding\n",
    "     - Processes each audio file\n",
    "     - Generates and saves transcriptions\n",
    "  3. Tracks unsupported languages\n",
    "\n",
    "### Output:\n",
    "- `transcriptions.pkl`: A dictionary mapping file names to transcriptions\n",
    "- `unsupported_languages.pkl`: List of languages not supported by Whisper\n",
    "\n",
    "### Notes:\n",
    "- The Whisper model supports multilingual transcription\n",
    "- Results are saved periodically to prevent data loss during long processing runs\n",
    "- Language-specific decoder prompts improve transcription accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3d99e3",
   "metadata": {},
   "source": [
    "## 4. Translation Pipeline (`get_translations.ipynb`)\n",
    "\n",
    "This notebook translates the transcriptions to English, making the content accessible regardless of the original language.\n",
    "\n",
    "### Key components:\n",
    "\n",
    "- **Model**: Facebook's `nllb-200-distilled-600M` (No Language Left Behind)\n",
    "- **Data**: Uses transcriptions from the previous step in `full_db.csv`\n",
    "- **Process**:\n",
    "  1. Maps language names to model-specific language codes\n",
    "  2. For each language:\n",
    "     - Creates a translation pipeline for that language to English\n",
    "     - Translates all transcriptions for that language\n",
    "     - Handles missing or unavailable languages\n",
    "  3. Merges translations back into the dataset\n",
    "\n",
    "### Output:\n",
    "- `results_trans4.pkl` and `results_trans5.pkl`: Intermediate translation results\n",
    "- `full_db1.csv`: Final dataset with original transcriptions and English translations\n",
    "\n",
    "### Notes:\n",
    "- The NLLB model supports 200+ languages\n",
    "- Translations are done in batches by language\n",
    "- The pipeline handles cases where translation isn't possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fae373",
   "metadata": {},
   "source": [
    "## 5. Content Analysis and Tagging (`blind_wiki_test.ipynb`)\n",
    "\n",
    "This notebook explores text analysis techniques to process transcriptions, including preprocessing and embedding generation for potential tagging.\n",
    "\n",
    "### Key components:\n",
    "\n",
    "- **Speech-to-Text**: Tests Whisper models for Spanish transcription\n",
    "- **Text Preprocessing**:\n",
    "  1. Tokenization\n",
    "  2. Punctuation removal\n",
    "  3. Stop word removal\n",
    "  4. Lemmatization\n",
    "- **Embedding Generation**:\n",
    "  - Word2Vec embeddings for tokens\n",
    "  - Average embeddings for document representation\n",
    "- **Tag Analysis**:\n",
    "  - Processes existing tags from the BlindWiki platform\n",
    "  - Removes special characters\n",
    "  - Filters for relevant tokens\n",
    "\n",
    "### Notes:\n",
    "- This notebook is more experimental, testing approaches for content understanding\n",
    "- Could be used to automatically suggest tags based on audio content\n",
    "- Uses Spanish-specific NLP tools for preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3647eb22",
   "metadata": {},
   "source": [
    "## Complete Pipeline Flow\n",
    "\n",
    "Here's how the components work together:\n",
    "\n",
    "1. **Audio Collection**: Voice notes are collected through the BlindWiki application\n",
    "\n",
    "2. **Language Identification**: Each audio file is analyzed to determine its language\n",
    "\n",
    "3. **Statistical Analysis**: Language distribution is analyzed to understand the dataset\n",
    "\n",
    "4. **Transcription**: Audio files are transcribed based on their identified language\n",
    "\n",
    "5. **Translation**: Transcriptions are translated to English for universal accessibility\n",
    "\n",
    "6. **Content Analysis**: Text is analyzed for meaningful content and potential tagging\n",
    "\n",
    "7. **Integration**: Results can be integrated back into the BlindWiki platform\n",
    "\n",
    "This pipeline enables automatic processing of multilingual audio content, making it more accessible and searchable within the BlindWiki ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe776c",
   "metadata": {},
   "source": [
    "## Future Work and Improvements\n",
    "\n",
    "Based on the current implementation, here are potential areas for improvement:\n",
    "\n",
    "1. **Model Upgrades**:\n",
    "   - Use larger Whisper models for better transcription accuracy\n",
    "   - Explore fine-tuning on domain-specific audio\n",
    "\n",
    "2. **Pipeline Integration**:\n",
    "   - Create an automated end-to-end pipeline\n",
    "   - Add API endpoints for real-time processing\n",
    "\n",
    "3. **Tag Generation**:\n",
    "   - Implement automatic tagging based on content\n",
    "   - Use topic modeling or keyword extraction\n",
    "\n",
    "4. **User Feedback**:\n",
    "   - Create mechanisms for users to correct transcriptions/translations\n",
    "   - Use this feedback to improve models\n",
    "\n",
    "5. **Performance Optimization**:\n",
    "   - Optimize for mobile devices\n",
    "   - Add caching mechanisms for frequently accessed content\n",
    "\n",
    "6. **Database Integration**:\n",
    "   - Move from file-based storage to a proper database\n",
    "   - Implement efficient search and retrieval\n",
    "\n",
    "7. **Content Summarization**:\n",
    "   - Add automatic summarization of longer recordings\n",
    "   - Generate short descriptions for improved browsability"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
