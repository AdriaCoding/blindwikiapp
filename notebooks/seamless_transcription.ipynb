{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97a15886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for MP3 files in: c:\\Users\\Adria\\dev\\blindwikiapp\\notebooks\\uploads\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoProcessor, SeamlessM4Tv2ForSpeechToText\n",
    "\n",
    "# Set device (CPU/GPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set up directories\n",
    "base_dir = os.path.dirname(os.getcwd())\n",
    "uploads_dir = os.path.join(os.getcwd(), \"uploads\")\n",
    "data_dir = os.path.join(os.getcwd(), \"data\")\n",
    "\n",
    "# Create the data and translated directories if they don't exist\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Looking for MP3 files in: {uploads_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "787e0a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:01<00:00,  1.94it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"facebook/seamless-m4t-v2-large\"\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = SeamlessM4Tv2ForSpeechToText.from_pretrained(model_name).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eafc2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(file_path, target_lang=\"eng\"):\n",
    "    \"\"\"\n",
    "    Transcribe un archivo de audio usando el modelo SeamlessM4T.\n",
    "    Args:\n",
    "        file_path (str): Ruta al archivo de audio\n",
    "        target_lang (str): Código del idioma de destino (por defecto: 'en')\n",
    "    Returns:\n",
    "        str: Transcripción del audio\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Cargar archivo de audio\n",
    "        waveform, sample_rate = librosa.load(file_path, sr=16000, mono=True)\n",
    "        \n",
    "        # Convertir array numpy a tensor de torch\n",
    "        audio_tensor = torch.tensor(waveform).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Preparar entrada para el modelo\n",
    "        inputs = processor(\n",
    "            audios=audio_tensor,\n",
    "            sampling_rate=sample_rate,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(device)\n",
    "        \n",
    "        # Generar transcripción\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inputs, tgt_lang=target_lang)\n",
    "            transcription = processor.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "        \n",
    "        return transcription\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {file_path}: {str(e)}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1249062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 MP3 files to process\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: acoruna_barco_m67780_a84524_audio_converted.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:08<00:42,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción completada para: acoruna_barco_m67780_a84524_audio_converted.mp3\n",
      "--------------------------------------------------------------------------------\n",
      "Processing: barcelona_JuanNuez_m70566_a87310_audio_converted.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:13<00:24,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción completada para: barcelona_JuanNuez_m70566_a87310_audio_converted.mp3\n",
      "--------------------------------------------------------------------------------\n",
      "Processing: barcelona_Ovvero_m68255_a84999_audio_converted.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:23<00:24,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción completada para: barcelona_Ovvero_m68255_a84999_audio_converted.mp3\n",
      "--------------------------------------------------------------------------------\n",
      "Processing: berlin_Dirk_m67384_a84128_audio_converted.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:41<00:24, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción completada para: berlin_Dirk_m67384_a84128_audio_converted.mp3\n",
      "--------------------------------------------------------------------------------\n",
      "Processing: cuenca_Amalia_m69879_a86623_audio_converted.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [01:02<00:15, 15.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción completada para: cuenca_Amalia_m69879_a86623_audio_converted.mp3\n",
      "--------------------------------------------------------------------------------\n",
      "Processing: elbarcelonC3A8s_Martagosa_m71623_a88367_audio_converted.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:18<00:00, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcripción completada para: elbarcelonC3A8s_Martagosa_m71623_a88367_audio_converted.mp3\n",
      "--------------------------------------------------------------------------------\n",
      "                                                file  \\\n",
      "0    acoruna_barco_m67780_a84524_audio_converted.mp3   \n",
      "1  barcelona_JuanNuez_m70566_a87310_audio_convert...   \n",
      "2  barcelona_Ovvero_m68255_a84999_audio_converted...   \n",
      "3      berlin_Dirk_m67384_a84128_audio_converted.mp3   \n",
      "4    cuenca_Amalia_m69879_a86623_audio_converted.mp3   \n",
      "\n",
      "                                       transcription  \n",
      "0      In this area, we have three disability seats.  \n",
      "1                          Well, we are in the mall.  \n",
      "2  It's already recorded, so it's best to get on ...  \n",
      "3  So there is a crossing here and next to the tr...  \n",
      "4  As you walk down the street you find a plastic...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Find all MP3 files in the uploads directory\n",
    "mp3_files = glob.glob(os.path.join(uploads_dir, \"*.mp3\"))\n",
    "print(f\"Found {len(mp3_files)} MP3 files to process\")\n",
    "\n",
    "# Create dictionary to store results\n",
    "results = {\n",
    "    'file': [],\n",
    "    'transcription': []\n",
    "}\n",
    "\n",
    "# Process each file\n",
    "for file_path in tqdm(mp3_files):  # Using regular tqdm, not tqdm.notebook\n",
    "    file_name = os.path.basename(file_path)\n",
    "    print(f\"Processing: {file_name}\")\n",
    "    \n",
    "    transcription = transcribe_audio(file_path)\n",
    "    \n",
    "    results['file'].append(file_name)\n",
    "    results['transcription'].append(transcription if transcription else \"ERROR\")\n",
    "    \n",
    "    # Imprimir progreso\n",
    "    if transcription:\n",
    "        print(f\"Transcripción completada para: {file_name}\")\n",
    "    else:\n",
    "        print(\"Transcripción fallida.\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Crear un DataFrame con los resultados\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90b58211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en c:\\Users\\Adria\\dev\\blindwikiapp\\notebooks\\data\\transcriptions.csv\n",
      "Se transcribieron exitosamente 6 de 6 archivos\n"
     ]
    }
   ],
   "source": [
    "# Guardar los resultados en un archivo CSV\n",
    "output_path = os.path.join(data_dir, \"transcriptions.csv\")\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"Resultados guardados en {output_path}\")\n",
    "\n",
    "# Contar cuántos archivos fueron transcritos exitosamente\n",
    "success_count = len(df[df['transcription'] != \"ERROR\"])\n",
    "print(f\"Se transcribieron exitosamente {success_count} de {len(mp3_files)} archivos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
